epoch, train_loss, test_loss, 1_precision, 1_recall, 1_f1-score, 2_precision, 2_recall, 2_f1-score, accuracy
1,0.963313400745392,1.20836925506592,0.272727272727273,1,0.428571428571429,0,0,0,0.272727272727273
2,0.878348688284556,0.539062321186066,0.5,1,0.666666666666667,1,0.625,0.769230769230769,0.727272727272727
3,0.775218486785889,0.631410360336304,0.428571428571429,1,0.6,1,0.5,0.666666666666667,0.636363636363636
4,0.517151017983754,0.359885513782501,1,1,1,1,1,1,1
5,0.402895217140516,0.20709003508091,1,1,1,1,1,1,1
6,0.202958658337593,0.06116671487689,1,1,1,1,1,1,1
7,0.069612486598392,0.125770792365074,1,1,1,1,1,1,1
8,0.240573433887524,0.002063097897917,1,1,1,1,1,1,1
9,0.096520657030245,0.007801444735378,1,1,1,1,1,1,1
10,0.088725867681205,0.123134024441242,1,1,1,1,1,1,1
11,0.063691268403394,0.038812879472971,1,1,1,1,1,1,1
12,0.015788400545716,0.006229150574654,1,1,1,1,1,1,1
13,0.105948622357876,0.017749011516571,1,1,1,1,1,1,1
14,0.070694286376238,0.043228514492512,1,1,1,1,1,1,1
15,0.096250408639511,0.014337844215334,1,1,1,1,1,1,1
16,0.051685733022168,0.002833522856236,1,1,1,1,1,1,1
17,0.058958425458513,0.00250217015855,1,1,1,1,1,1,1
18,0.734648354351521,0.06370709091425,1,1,1,1,1,1,1
19,0.204755296309789,0.391302496194839,0.875,0.933333333333333,0.909090909090909,1,1,1,1
20,0.178072701829175,0.28270873427391,1,1,1,1,1,1,1
21,0.165042228996754,0.154595375061035,1,1,1,1,1,1,1
22,0.070622420869768,0.053311869502068,1,1,1,1,1,1,1
23,0.031666783460726,0.011140149086714,1,1,1,1,1,1,1
24,0.060694698175212,0.007932947017252,1,1,1,1,1,1,1
25,0.059965036233431,0.011692404747009,1,1,1,1,1,1,1
26,0.062155994234975,0.018585436046124,1,1,1,1,1,1,1
27,0.034153303441902,0.018011126667261,1,1,1,1,1,1,1
28,0.051956726238132,0.011604222469032,1,1,1,1,1,1,1
29,0.039763268083334,0.009221628308296,1,1,1,1,1,1,1
30,0.010853518305036,0.00656712660566,1,1,1,1,1,1,1
31,0.045135025517084,0.00910431612283,1,1,1,1,1,1,1
32,0.006734787782686,0.008766144514084,1,1,1,1,1,1,1
